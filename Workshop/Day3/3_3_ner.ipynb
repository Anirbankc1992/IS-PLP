{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_V-y0WHzpej5"
   },
   "source": [
    "\n",
    "# TA Workshop: POS Tagging and Lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srm194oXpej_",
    "outputId": "de03036e-0ef8-4f4f-a938-7bf8fba7d6b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anirban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\anirban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szLktldcpekA",
    "outputId": "7f0e7e1d-96b3-4985-e9a5-b07cb19ab306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Professor', 'NNP'),\n",
       " ('Tan', 'NNP'),\n",
       " ('Eng', 'NNP'),\n",
       " ('Chye', 'NNP'),\n",
       " (',', ','),\n",
       " ('NUS', 'NNP'),\n",
       " ('Deputy', 'NNP'),\n",
       " ('President', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Provost', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('Professor', 'NNP'),\n",
       " ('Menahem', 'NNP'),\n",
       " ('Ben-Sasson', 'NNP'),\n",
       " (',', ','),\n",
       " ('President', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('HUJ', 'NNP'),\n",
       " ('signed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('joint', 'JJ'),\n",
       " ('degree', 'NN'),\n",
       " ('agreement', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('NUS', 'NNP'),\n",
       " (',', ','),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('presence', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Ambassador', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Israel', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('Singapore', 'NNP'),\n",
       " ('Her', 'NNP'),\n",
       " ('Excellency', 'NNP'),\n",
       " ('Amira', 'NNP'),\n",
       " ('Arnon', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('about', 'IN'),\n",
       " ('30', 'CD'),\n",
       " ('invited', 'JJ'),\n",
       " ('guests', 'NNS'),\n",
       " (',', ','),\n",
       " ('on', 'IN'),\n",
       " ('July', 'NNP'),\n",
       " ('03', 'CD'),\n",
       " (',', ','),\n",
       " ('2013', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== POS Tagging and NER using NLTK =====\n",
    "\n",
    "sent = '''Professor Tan Eng Chye, NUS Deputy President and Provost, and Professor \\\n",
    "Menahem Ben-Sasson, President of HUJ signed the joint degree agreement at NUS, \\\n",
    "in the presence of Ambassador of Israel to Singapore Her Excellency Amira Arnon \\\n",
    "and about 30 invited guests, on July 03, 2013.'''\n",
    "\n",
    "# The input for the NE Chunker needs to have POS tags.\n",
    "# The input for POS tagger needs to be tokenized first.\n",
    "sent_pos = pos_tag(word_tokenize(sent))\n",
    "sent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIgBkyZ8pekB",
    "outputId": "fbc7200d-755b-4ac2-9d2f-1f18c27ab6de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\anirban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\anirban\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Professor/NNP\n",
      "  Tan/NNP\n",
      "  Eng/NNP\n",
      "  Chye/NNP\n",
      "  ,/,\n",
      "  (ORGANIZATION NUS/NNP)\n",
      "  Deputy/NNP\n",
      "  President/NNP\n",
      "  and/CC\n",
      "  (ORGANIZATION Provost/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  (ORGANIZATION Professor/NNP Menahem/NNP)\n",
      "  Ben-Sasson/NNP\n",
      "  ,/,\n",
      "  President/NNP\n",
      "  of/IN\n",
      "  (ORGANIZATION HUJ/NNP)\n",
      "  signed/VBD\n",
      "  the/DT\n",
      "  joint/JJ\n",
      "  degree/NN\n",
      "  agreement/NN\n",
      "  at/IN\n",
      "  (ORGANIZATION NUS/NNP)\n",
      "  ,/,\n",
      "  in/IN\n",
      "  the/DT\n",
      "  presence/NN\n",
      "  of/IN\n",
      "  (ORGANIZATION Ambassador/NNP)\n",
      "  of/IN\n",
      "  (GPE Israel/NNP)\n",
      "  to/TO\n",
      "  (GPE Singapore/NNP)\n",
      "  Her/NNP\n",
      "  Excellency/NNP\n",
      "  (PERSON Amira/NNP Arnon/NNP)\n",
      "  and/CC\n",
      "  about/IN\n",
      "  30/CD\n",
      "  invited/JJ\n",
      "  guests/NNS\n",
      "  ,/,\n",
      "  on/IN\n",
      "  July/NNP\n",
      "  03/CD\n",
      "  ,/,\n",
      "  2013/CD\n",
      "  ./.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "sent_chunk = ne_chunk(sent_pos)\n",
    "print(sent_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6Fhn-_iYpekB"
   },
   "outputs": [],
   "source": [
    "# ===== Now try creating your own named entity and noun phrase chunker ====\n",
    "# We need to define the tag patterns to capture the target phrases and use \n",
    "# RegexParser to chunk the input with those patterns.\n",
    "# Some minimal tag patterns are given here. \n",
    "\n",
    "grammar = r\"\"\"\n",
    "  NE: {<NNP>+}      # chunk NE sequences of proper nouns\n",
    "  NP: {<DT><NN|NNS>}\n",
    "   # chunk noun phrase by DT+NN  \n",
    "      \n",
    "\"\"\"\n",
    "\n",
    "cp = nltk.RegexpParser(grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spc7Xb0WpekC",
    "outputId": "c2236b63-e550-40d2-b8e3-7b218418579d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NE Donald/NNP Trump/NNP) is/VBZ (NP a/DT president/NN) ./.)\n"
     ]
    }
   ],
   "source": [
    "# Try it on a simple sentence.\n",
    "result = cp.parse(pos_tag(word_tokenize(\"Donald Trump is a president.\"))) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBlECY_102o_",
    "outputId": "eb0ccfe1-0aac-4760-bec9-2f473a935c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               S                                         \n",
      "   ____________|__________________________                \n",
      "  |     |              NE                 NP             \n",
      "  |     |       _______|______        ____|_______        \n",
      "is/VBZ ./. Donald/NNP     Trump/NNP a/DT     president/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The following line would create a graph with the tree if run locally.\n",
    "# It doesn't work in Colab.\n",
    "#result.draw()\n",
    "\n",
    "# a work-around, not always correct\n",
    "from nltk import Tree\n",
    "Tree.fromstring(str(result)).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDY_hb0QpekC",
    "outputId": "b9fe8d52-1f1b-4b2c-a221-89eb7196a0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NE Professor/NNP Tan/NNP Eng/NNP Chye/NNP)\n",
      "  ,/,\n",
      "  (NE NUS/NNP Deputy/NNP President/NNP)\n",
      "  and/CC\n",
      "  (NE Provost/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  (NE Professor/NNP Menahem/NNP Ben-Sasson/NNP)\n",
      "  ,/,\n",
      "  (NE President/NNP)\n",
      "  of/IN\n",
      "  (NE HUJ/NNP)\n",
      "  signed/VBD\n",
      "  the/DT\n",
      "  joint/JJ\n",
      "  degree/NN\n",
      "  agreement/NN\n",
      "  at/IN\n",
      "  (NE NUS/NNP)\n",
      "  ,/,\n",
      "  in/IN\n",
      "  (NP the/DT presence/NN)\n",
      "  of/IN\n",
      "  (NE Ambassador/NNP)\n",
      "  of/IN\n",
      "  (NE Israel/NNP)\n",
      "  to/TO\n",
      "  (NE Singapore/NNP Her/NNP Excellency/NNP Amira/NNP Arnon/NNP)\n",
      "  and/CC\n",
      "  about/IN\n",
      "  30/CD\n",
      "  invited/JJ\n",
      "  guests/NNS\n",
      "  ,/,\n",
      "  on/IN\n",
      "  (NE July/NNP)\n",
      "  03/CD\n",
      "  ,/,\n",
      "  2013/CD\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Now try it on the longer sentence with more noun phrases.\n",
    "result = cp.parse(sent_pos)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0sPd3klpekD"
   },
   "source": [
    "\n",
    "# Exercise: \n",
    "Modify the above tag patterns to capture the NEs and NPs in the example sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLbvAC4VpekD"
   },
   "source": [
    "# Alternative way: using spaCY\n",
    "\n",
    "Installation of spaCY and the required models:\n",
    "    pip install -U spacy\n",
    "    python -m spacy download en_core_web_sm\n",
    "    python -m spacy download en_core_web_md\n",
    "\n",
    "Restart the kernel after the above steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNd-UESLpekD",
    "outputId": "e2761b43-3445-43ca-f7d4-f93b2721008d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\anaconda\\envs\\anirban\\lib\\site-packages (2.3.1)\n",
      "Collecting spacy"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.5.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.0 which is incompatible.\n",
      "gensim 3.8.3 requires Cython==0.29.14, but you have cython 0.29.22 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading spacy-3.1.0-cp37-cp37m-win_amd64.whl (11.8 MB)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp37-cp37m-win_amd64.whl (450 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (4.47.0)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (3.7.4.2)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.7\n",
      "  Downloading thinc-8.0.7-cp37-cp37m-win_amd64.whl (1.0 MB)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Collecting catalogue<2.1.0,>=2.0.4\n",
      "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (20.9)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.7\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from catalogue<2.1.0,>=2.0.4->spacy) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.1.0-py3-none-any.whl (57 kB)\n",
      "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: typing-extensions, catalogue, wasabi, typer, srsly, smart-open, pydantic, thinc, spacy-legacy, pathy, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.2\n",
      "    Uninstalling typing-extensions-3.7.4.2:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.2\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 1.0.0\n",
      "    Uninstalling catalogue-1.0.0:\n",
      "      Successfully uninstalled catalogue-1.0.0\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 0.7.0\n",
      "    Uninstalling wasabi-0.7.0:\n",
      "      Successfully uninstalled wasabi-0.7.0\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 1.0.2\n",
      "    Uninstalling srsly-1.0.2:\n",
      "      Successfully uninstalled srsly-1.0.2\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 2.1.0\n",
      "    Uninstalling smart-open-2.1.0:\n",
      "      Successfully uninstalled smart-open-2.1.0\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 7.4.1\n",
      "    Uninstalling thinc-7.4.1:\n",
      "      Successfully uninstalled thinc-7.4.1\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 2.3.1\n",
      "    Uninstalling spacy-2.3.1:\n",
      "      Successfully uninstalled spacy-2.3.1\n",
      "Successfully installed catalogue-2.0.4 pathy-0.6.0 pydantic-1.8.2 smart-open-5.1.0 spacy-3.1.0 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.7 typer-0.3.2 typing-extensions-3.10.0.0 wasabi-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-TaSti4pekE",
    "outputId": "0ef1833f-1421-4a60-d9c9-769c9a080e22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.1.0/en_core_web_md-3.1.0-py3-none-any.whl (45.4 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from en-core-web-md==3.1.0) (3.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (20.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.47.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.7)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.4.1)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.10.0.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.19.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.1.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 14:43:54.088135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-07-17 14:43:54.088654: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhIpq_A-pekE",
    "outputId": "11e3797a-716b-442a-f25a-c5b981fb1aff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x110b0065dc8>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x110b05399a8>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x110b0290dd8>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x110b05da8c8>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x110b05e9488>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x110b0290f28>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "#load the required model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AwYueygqpekE"
   },
   "outputs": [],
   "source": [
    "#process a sentence\n",
    "result = nlp(\"James likes the nice gift very much.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t-IFCeLYpekF"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "3nMPvS9ppekF",
    "outputId": "f9b16086-7efc-4747-f02d-cc2d2cf80372"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c129239052c14b70a64992a108a370df-0\" class=\"displacy\" width=\"1275\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">James</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">likes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">nice</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">gift</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">very</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">much.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c129239052c14b70a64992a108a370df-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c129239052c14b70a64992a108a370df-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c129239052c14b70a64992a108a370df-0-1\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c129239052c14b70a64992a108a370df-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c129239052c14b70a64992a108a370df-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c129239052c14b70a64992a108a370df-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c129239052c14b70a64992a108a370df-0-3\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c129239052c14b70a64992a108a370df-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,354.0 L753.0,342.0 737.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c129239052c14b70a64992a108a370df-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c129239052c14b70a64992a108a370df-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c129239052c14b70a64992a108a370df-0-5\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 1100.0,2.0 1100.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c129239052c14b70a64992a108a370df-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,354.0 L1108.0,342.0 1092.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to display the parsing result as dependency graph\n",
    "displacy.render(result, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uchRj-vHpekG",
    "outputId": "62ee3917-184a-43b5-fce7-76e249a9f974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James James PROPN NNP nsubj likes Xxxxx True False\n",
      "likes like VERB VBZ ROOT likes xxxx True False\n",
      "the the DET DT det gift xxx True True\n",
      "nice nice ADJ JJ amod gift xxxx True False\n",
      "gift gift NOUN NN dobj likes xxxx True False\n",
      "very very ADV RB advmod much xxxx True True\n",
      "much much ADV RB advmod likes xxxx True True\n",
      ". . PUNCT . punct likes . False False\n"
     ]
    }
   ],
   "source": [
    "#detailed results for each token\n",
    "for token in result:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.head,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znZG6xkBIBxr",
    "outputId": "fd04b479-d967-4799-b64b-e69ede33ac3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James NounType=Prop|Number=Sing\n",
      "likes Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "the Definite=Def|PronType=Art\n",
      "nice Degree=Pos\n",
      "gift Number=Sing\n",
      "very \n",
      "much \n",
      ". PunctType=Peri\n"
     ]
    }
   ],
   "source": [
    "# Each token carries detailed morphological information\n",
    "for token in result:\n",
    "  print(token.text, token.morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "Xn2CWKqbpekF",
    "outputId": "d77b2a53-8496-4782-e6d2-b99f313e0d62",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Professor \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tan Eng Chye\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", NUS Deputy President and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Provost\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", and Professor \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Menahem Ben-Sasson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", President of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    HUJ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " signed the joint degree agreement at NUS, in the presence of Ambassador of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Israel\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Singapore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " Her Excellency \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amira Arnon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    about 30\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " invited guests, on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    July 03\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2013\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result1 = nlp(sent)\n",
    "displacy.render(result1, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUh-dveppekG",
    "outputId": "0405e7ca-5b26-4cb8-a870-2e6f6fce0c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tan Eng Chye 10 22 PERSON\n",
      "Provost 49 56 PERSON\n",
      "Menahem Ben-Sasson 72 90 PERSON\n",
      "HUJ 105 108 ORG\n",
      "Israel 184 190 GPE\n",
      "Singapore 194 203 GPE\n",
      "Amira Arnon 219 230 PERSON\n",
      "about 30 235 243 CARDINAL\n",
      "July 03 263 270 DATE\n",
      "2013 272 276 DATE\n"
     ]
    }
   ],
   "source": [
    "# and the results of NER\n",
    "for ent in result1.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xN4s-P5tpekG"
   },
   "outputs": [],
   "source": [
    "# Now let's work on an article. Upload the file to your Colab session first.\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "f =  open(\"IE-example.txt\", \"r\")\n",
    "text = f.read()\n",
    "\n",
    "sents = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5vUGzmJEpekG"
   },
   "outputs": [],
   "source": [
    "# Disable the pipeline components that you don't need.\n",
    "# Process multiple sentences more efficiently using pipe()\n",
    "\n",
    "results = nlp.pipe(sents, disable=[\"parser\"])\n",
    "res_list = list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKN-IaKdpekH",
    "outputId": "441ca8ef-11f0-47b0-fd4b-253e71ef7d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hilary Clinton PERSON\n",
      "Donald Trump PERSON\n",
      "Russia GPE\n",
      "ISIS ORG\n",
      "Clinton PERSON\n",
      "Trump PERSON\n",
      "Russian NORP\n",
      "Vladimir Putin PERSON\n",
      "Trump PERSON\n",
      "NBC News ORG\n",
      "Putin PERSON\n",
      "US GPE\n",
      "Barack Obama PERSON\n",
      "Trump ORG\n",
      "US GPE\n",
      "ISIS ORG\n",
      "Pentagon ORG\n",
      "Obama GPE\n",
      "Barack Obama PERSON\n",
      "Hillary Clinton PERSON\n",
      "Clinton PERSON\n",
      "Iraq GPE\n",
      "Syria GPE\n"
     ]
    }
   ],
   "source": [
    "for res in res_list:\n",
    "    for ent in res.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGw6UMaPElf8",
    "outputId": "4609d2c5-171f-4ac8-cffc-3a390d2f42af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James True\n",
      "likes True\n",
      "oranges True\n",
      "and True\n",
      "peaches True\n",
      ". True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = nlp(\"James likes oranges and peaches.\")\n",
    "for tok in result:\n",
    "  print(tok.text, tok.has_vector)\n",
    "\n",
    "tok.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GfIXSR6HN0S",
    "outputId": "171c49e6-2fdd-4bd2-9388-9feffd6678ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12540577\n",
      "0.73022324\n"
     ]
    }
   ],
   "source": [
    "print(result[2].similarity(result[0]))\n",
    "print(result[2].similarity(result[4]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.3-ner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
