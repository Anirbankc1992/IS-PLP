{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2i8dAnylyi2",
    "outputId": "3a1cac15-9c6a-4f38-81f4-20c4b638815d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\anaconda\\envs\\anirban\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: joblib in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: regex in c:\\anaconda\\envs\\anirban\\lib\\site-packages (from nltk) (2020.6.8)\n"
     ]
    }
   ],
   "source": [
    "# Colab environment already has nltk\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MEE3zRYnlyjB"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "TA Workshop : Text preparation step by step\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpVHm89FlyjC",
    "outputId": "b5f69dec-fb20-461d-b453-b20da8bed659"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anirban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anirban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anirban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load required data for NLTK \n",
    "## Note: on local machine, you just need to run it once only using \"nltk.download()\"\n",
    "##       at the 'NLTK Downloader' dialogue window, choose 'book', then click 'Download'\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 records and 3 columns\n"
     ]
    }
   ],
   "source": [
    "# Open the text data file from your current working directory\n",
    "data = open(\"osha.txt\", \"r\")\n",
    "docslist = data.readlines()\n",
    "\n",
    "listRows = []\n",
    "for row in docslist:\n",
    "    listRows.append(row.split('\\t'))\n",
    "\n",
    "df = pd.DataFrame(listRows)\n",
    "df.columns = ['Date','Title','Description']\n",
    "\n",
    "print(\"There are %d records and %d columns\"%(df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Title_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201079928</td>\n",
       "      <td>Employee Is Burned By Forklift Radiator Fluid</td>\n",
       "      <td>At approximately 11:30 a.m. on November 13  2...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202561825</td>\n",
       "      <td>Employee Falls From Flatbed Trailer And Later...</td>\n",
       "      <td>On August 30  2013  Employee #1 was working f...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200361855</td>\n",
       "      <td>Two Workers Are Struck By Motor Vehicle And O...</td>\n",
       "      <td>On August 27  2013  Employees #1 and #2  of T...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200361863</td>\n",
       "      <td>Employee Is Struck By Bales Of Wire And Killed</td>\n",
       "      <td>On August 26  2013  Employee #1  with Lee Iro...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201079324</td>\n",
       "      <td>Employee Is Splashed With Hot Water And Is Bu...</td>\n",
       "      <td>On July 14  2013  Employee #1  vacuum pump tr...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202658258</td>\n",
       "      <td>Employee Suffers Burns While Moving Soup</td>\n",
       "      <td>On June 30  2013  Employee #1 was working in ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202685947</td>\n",
       "      <td>Employee Injures Self With Knife</td>\n",
       "      <td>An incident occurred as Employee #1 was attem...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202673471</td>\n",
       "      <td>Foreman Is Fatally Crushed When Forklift Tips...</td>\n",
       "      <td>At approximately 6:30 a.m. on May 13  2013  E...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202369575</td>\n",
       "      <td>Employee Fractures Abdomen When Run Over By T...</td>\n",
       "      <td>On April 23  2013  Employee #1  a baggage tug...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202509832</td>\n",
       "      <td>Employee Suffers Abdominal Fracture In Fall F...</td>\n",
       "      <td>On April 9  2013  Employee #1 was installing ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                              Title  \\\n",
       "0  201079928     Employee Is Burned By Forklift Radiator Fluid    \n",
       "1  202561825   Employee Falls From Flatbed Trailer And Later...   \n",
       "2  200361855   Two Workers Are Struck By Motor Vehicle And O...   \n",
       "3  200361863    Employee Is Struck By Bales Of Wire And Killed    \n",
       "4  201079324   Employee Is Splashed With Hot Water And Is Bu...   \n",
       "5  202658258          Employee Suffers Burns While Moving Soup    \n",
       "6  202685947                  Employee Injures Self With Knife    \n",
       "7  202673471   Foreman Is Fatally Crushed When Forklift Tips...   \n",
       "8  202369575   Employee Fractures Abdomen When Run Over By T...   \n",
       "9  202509832   Employee Suffers Abdominal Fracture In Fall F...   \n",
       "\n",
       "                                         Description  Title_Length  \n",
       "0   At approximately 11:30 a.m. on November 13  2...             6  \n",
       "1   On August 30  2013  Employee #1 was working f...             7  \n",
       "2   On August 27  2013  Employees #1 and #2  of T...            10  \n",
       "3   On August 26  2013  Employee #1  with Lee Iro...             8  \n",
       "4   On July 14  2013  Employee #1  vacuum pump tr...             8  \n",
       "5   On June 30  2013  Employee #1 was working in ...             5  \n",
       "6   An incident occurred as Employee #1 was attem...             4  \n",
       "7   At approximately 6:30 a.m. on May 13  2013  E...             7  \n",
       "8   On April 23  2013  Employee #1  a baggage tug...             8  \n",
       "9   On April 9  2013  Employee #1 was installing ...             7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title_Length'] = df['Title'].apply(lambda x: len(x.split())-1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 390 titles with single word description\n"
     ]
    }
   ],
   "source": [
    "print('There are {} titles with single word description'.format(len(df[df['Title_Length']==1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "804"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['number_of_tokens'] = df.Description.apply(lambda x: len(word_tokenize(x)))\n",
    "df['number_of_tokens'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['InspectionOpen DateSICEstablishment Name\\n'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['number_of_tokens']==3]['Description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    " \n",
    "\n",
    "class StemmerTokenizer(object):\n",
    "    def _init_(self):\n",
    "        self.stemmer = SnowballStemmer(language='english')\n",
    "        self.stop = set(stopwords.words('english'))\n",
    "\n",
    " \n",
    "\n",
    "    def _call_(self, doc):\n",
    "        # Remove special characters and hybrid word-punctuation characters\n",
    "        doc = re.sub(r\"[^A-Za-z0-9]\", \" \", doc)\n",
    "\n",
    " \n",
    "\n",
    "        # tokenize text into word tokens\n",
    "        tokens = word_tokenize(doc)\n",
    "\n",
    " \n",
    "\n",
    "        # strip out punctuation & integers\n",
    "        words = [t for t in tokens if t.isalpha()]\n",
    "\n",
    "\n",
    "        #convert to lowercase\n",
    "        words = [t.lower() for t in words]\n",
    "        \n",
    "        # strip out stopwords\n",
    "        words = [t for t in words if t not in self.stop]\n",
    "        \n",
    "        # lemmatize each token\n",
    "        return [self.stemmer.stem(t) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1.1-StepByStep_v2.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
