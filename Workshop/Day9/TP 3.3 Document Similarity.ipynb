{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5M_yMUWzAK-n"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMTL5vkmAK-o"
   },
   "source": [
    "# Document similarity methods\n",
    "\n",
    "In this notebook, we illustrate different document similarity methods and use them to retrieve similar customer reviews. The method word movers' distance is illustrated. This method depends on word embeddings too, but also look at an 'individual words' viewpoint.\n",
    "\n",
    "## Word movers' distance\n",
    "\n",
    "WMD uses normalised word embeddings and Bag of words to calculate distance between sentences/ documents. It resolves the problem of synonyms between sentences. The intution behind the method is that we find the minimum \"traveling distance\" between documents, in other words the most efficient way to \"move\" the distribution of sentence/document 1 to the distribution of sentence/ document 2.\n",
    "\n",
    "A good illustration is the two sentences below:\n",
    "sentence_obama and sentence_president"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23504,
     "status": "ok",
     "timestamp": 1610525474898,
     "user": {
      "displayName": "Aobo Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1R4n3TLad19eGDFJcbKQpak37bv0BcjEpPoimgw=s64",
      "userId": "18082252328038546601"
     },
     "user_tz": -480
    },
    "id": "BxZOoFDOEmEs",
    "outputId": "3de71bd1-d158-4ad0-b588-619d150407c0"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fnKEO_eDAK-o"
   },
   "outputs": [],
   "source": [
    "# Image from https://vene.ro/images/wmd-obama.png\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from time import time\n",
    "\n",
    "#img = mpimg.imread('/content/drive/MyDrive/Colab Notebooks/images/wmd-obama.png')\n",
    "#imgplot = plt.imshow(img)\n",
    "#plt.axis('off')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nn7pzHKmAK-o"
   },
   "outputs": [],
   "source": [
    "# Initialize logging.\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "sentence_obama = 'Obama speaks to the media in Illinois'\n",
    "sentence_president = 'The president greets the press in Chicago'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okeNZbykAK-o"
   },
   "source": [
    "## Preprocessing\n",
    "First, let's do some pre-processing, removing stopwords and punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1610525712629,
     "user": {
      "displayName": "Aobo Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1R4n3TLad19eGDFJcbKQpak37bv0BcjEpPoimgw=s64",
      "userId": "18082252328038546601"
     },
     "user_tz": -480
    },
    "id": "f5CoWTmvAK-o",
    "outputId": "c690d3bc-09ed-4d60-914b-1efdf4a1527c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anirban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anirban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import and download stopwords from NLTK.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "download('stopwords')  # Download stopwords list.\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Pre-processing a document.\n",
    "from nltk import word_tokenize\n",
    "download('punkt')  # Download data for tokenizer.\n",
    "\n",
    "def preprocess(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    return doc\n",
    "\n",
    "sentence_obama = preprocess(sentence_obama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD4yYlwJAK-o"
   },
   "source": [
    "We will use the word vectors that are pre-trained and available from google. https://code.google.com/archive/p/word2vec/ They are hosted in gensim. These are from part of Google News dataset (about 100 billion words) with 300-dimensional vectors for 3 million words and phrases.\n",
    "\n",
    "More options:\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uDaKcqHXAK-o",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\pyakc\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "2021-10-17 19:33:06,695 : INFO : Creating C:\\Users\\anirban/gensim-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.4% 23.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=-------------------------------------------------] 3.5% 58.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==------------------------------------------------] 5.7% 94.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===-----------------------------------------------] 7.9% 131.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 10.1% 167.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======--------------------------------------------] 12.2% 202.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======-------------------------------------------] 14.3% 238.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========------------------------------------------] 16.4% 271.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========-----------------------------------------] 18.4% 306.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========----------------------------------------] 20.5% 340.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 22.4% 372.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============--------------------------------------] 24.4% 404.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============-------------------------------------] 26.4% 439.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============------------------------------------] 28.3% 471.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============-----------------------------------] 30.4% 505.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================----------------------------------] 32.4% 539.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 34.7% 577.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================--------------------------------] 37.2% 618.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================------------------------------] 40.1% 666.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================-----------------------------] 42.2% 701.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================----------------------------] 44.7% 742.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================---------------------------] 47.2% 785.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================--------------------------] 49.6% 825.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 52.1% 866.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================-----------------------] 54.9% 912.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================----------------------] 57.1% 949.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================---------------------] 59.6% 990.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================-------------------] 62.3% 1035.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================------------------] 64.5% 1072.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================-----------------] 66.8% 1110.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================----------------] 69.6% 1157.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================---------------] 71.8% 1194.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================================-------------] 74.5% 1238.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================------------] 77.2% 1283.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 79.3% 1318.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================----------] 81.8% 1359.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================================--------] 84.5% 1404.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================================-------] 86.7% 1442.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================------] 89.2% 1482.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 91.9% 1528.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================================---] 94.2% 1565.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================================--] 96.8% 1609.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 99.6% 1655.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "2021-10-17 19:36:19,595 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from C:\\\\Users\\\\anirban/gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2021-10-17T19:36:19.595242', 'gensim': '4.0.1', 'python': '3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyemd\n",
      "  Using cached pyemd-0.5.1.tar.gz (91 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in c:\\anaconda\\envs\\pyakc\\lib\\site-packages (from pyemd) (1.19.2)\n",
      "Building wheels for collected packages: pyemd\n",
      "  Building wheel for pyemd (setup.py): started\n",
      "  Building wheel for pyemd (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyemd\n",
      "Failed to build pyemd\n",
      "Installing collected packages: pyemd\n",
      "    Running setup.py install for pyemd: started\n",
      "    Running setup.py install for pyemd: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\anaconda\\envs\\pyakc\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\anirban\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pj0m0uqk\\\\pyemd\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\anirban\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pj0m0uqk\\\\pyemd\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\anirban\\AppData\\Local\\Temp\\pip-wheel-7fz78qfv'\n",
      "       cwd: C:\\Users\\anirban\\AppData\\Local\\Temp\\pip-install-pj0m0uqk\\pyemd\\\n",
      "  Complete output (11 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.7\n",
      "  creating build\\lib.win-amd64-3.7\\pyemd\n",
      "  copying pyemd\\__about__.py -> build\\lib.win-amd64-3.7\\pyemd\n",
      "  copying pyemd\\__init__.py -> build\\lib.win-amd64-3.7\\pyemd\n",
      "  running build_ext\n",
      "  building 'pyemd.emd' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyemd\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\anaconda\\envs\\pyakc\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\anirban\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pj0m0uqk\\\\pyemd\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\anirban\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pj0m0uqk\\\\pyemd\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\anirban\\AppData\\Local\\Temp\\pip-record-fhpwagcq\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\anaconda\\envs\\pyakc\\Include\\pyemd'\n",
      "         cwd: C:\\Users\\anirban\\AppData\\Local\\Temp\\pip-install-pj0m0uqk\\pyemd\\\n",
      "    Complete output (11 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.7\n",
      "    creating build\\lib.win-amd64-3.7\\pyemd\n",
      "    copying pyemd\\__about__.py -> build\\lib.win-amd64-3.7\\pyemd\n",
      "    copying pyemd\\__init__.py -> build\\lib.win-amd64-3.7\\pyemd\n",
      "    running build_ext\n",
      "    building 'pyemd.emd' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\anaconda\\envs\\pyakc\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\anirban\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pj0m0uqk\\\\pyemd\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\anirban\\\\AppData\\\\Local\\\\Temp\\\\pip-install-pj0m0uqk\\\\pyemd\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\anirban\\AppData\\Local\\Temp\\pip-record-fhpwagcq\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\anaconda\\envs\\pyakc\\Include\\pyemd' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyemd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82ecs-doAK-p"
   },
   "source": [
    "The WMD model is based on the word vectors, and can be obtained directly from the distance measure from the individual word vectors. Note the sentence on Obama and the president has a distance of 3.79. \n",
    "Note that similarity and distance are opposites. When the distance is high, the similarity is low. Vice versa is true as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1610526066485,
     "user": {
      "displayName": "Aobo Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1R4n3TLad19eGDFJcbKQpak37bv0BcjEpPoimgw=s64",
      "userId": "18082252328038546601"
     },
     "user_tz": -480
    },
    "id": "8O8e53-IAK-p",
    "outputId": "5cd260a4-9487-4aeb-cef8-b5422800085b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyemd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15620/105285898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwmdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_obama\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence_president\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'distance = %.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\pyakc\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mwmdistance\u001b[1;34m(self, document1, document2, norm)\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[1;31m# If pyemd C extension is available, import it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m         \u001b[1;31m# If pyemd is attempted to be used, but isn't installed, ImportError will be raised in wmdistance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 881\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mpyemd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0memd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m         \u001b[1;31m# Remove out-of-vocabulary words.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyemd'"
     ]
    }
   ],
   "source": [
    "distance = model.wmdistance(sentence_obama, sentence_president)\n",
    "print('distance = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZoVetx4AK-p"
   },
   "source": [
    "Notice that in another case with a very different sentence talking about oranges, the distance is bigger (less similar) at 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1610526069307,
     "user": {
      "displayName": "Aobo Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1R4n3TLad19eGDFJcbKQpak37bv0BcjEpPoimgw=s64",
      "userId": "18082252328038546601"
     },
     "user_tz": -480
    },
    "id": "BZeVWgneAK-p",
    "outputId": "3845eaa7-dd40-4f35-caca-b79dbfda7814"
   },
   "outputs": [],
   "source": [
    "sentence_orange = preprocess('Oranges are my favorite fruit')\n",
    "distance = model.wmdistance(sentence_obama, sentence_orange)\n",
    "print('distance = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYQ2m-fsPRKe"
   },
   "source": [
    "## Normalising WMD\n",
    " \n",
    "In the WMD distance, sentences of different lenghts can increase the distance. This is due to different word vectors lengths of the sentences. To mitigate this, the document vectors of the sentences are each normalised to the same dimension. The normalisation in this case reduces the distance lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wp8HHu60AK-p"
   },
   "outputs": [],
   "source": [
    "model.init_sims(replace=True)  # Normalizes the vectors in the word2vec class.\n",
    "\n",
    "distance = model.wmdistance(sentence_obama, sentence_president)  # Compute WMD as normal.\n",
    "print('distance: %r' % distance)\n",
    "\n",
    "distance = model.wmdistance(sentence_obama, sentence_orange)\n",
    "print('distance = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4QPo2TkR1lu"
   },
   "source": [
    "## Building our own word vectors\n",
    "\n",
    "Instead of using the word vectors from Google, we train our own word vectors in this yelp reviews case. This is in json format and in particular we look at 6 restaurant IDs. This reviews dataset is available from Kaggle. https://www.kaggle.com/yelp-dataset/yelp-dataset \n",
    "The following code reads in the reviews one by one into the wmd_corpus (only for the 6 restaurant IDs) and the w2v corpus (for training word vectors.)\n",
    "\n",
    "As always, training a new word vector model is advantageous since this trained model will reflect the semantics of this reviews case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bFREs3sAK-p"
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "import json\n",
    "\n",
    "# Review IDs of the restaurants.\n",
    "ids = ['fWKvX83p0-ka4JS3dc6E5A', 'IjZ33sJrzXqU-0X6U8NwyA', 'IESLBzqUCLdSzSqm0eCSxQ',\n",
    "      '1uJFq2r5QfJG_6ExMRCaGw', 'm2CKSsepBCoRYWxiRUsxAg', 'jJAIXA46pU1swYyRCdfXtQ']\n",
    "\n",
    "w2v_corpus = []  # Documents to train word2vec on (all 6 restaurants).\n",
    "wmd_corpus = []  # Documents to run queries against (only one restaurant).\n",
    "documents = []  # wmd_corpus, with no pre-processing (so we can see the original documents).\n",
    "with open('/content/drive/MyDrive/Colab Data/yelp_academic_dataset_review.json') as data_file: \n",
    "    for line in data_file:\n",
    "        json_line = json.loads(line)\n",
    "        if json_line['review_id'] not in ids:\n",
    "            # Not one of the 6 restaurants.\n",
    "            continue\n",
    "         \n",
    "        # Pre-process document.\n",
    "        text = json_line['text']  # Extract text from JSON object.\n",
    "        text = preprocess(text)\n",
    "        # Add to corpus for training Word2Vec.\n",
    "        w2v_corpus.append(text)\n",
    "\n",
    "        if json_line['review_id'] in ids:\n",
    "            # Add to corpus for similarity queries.\n",
    "            wmd_corpus.append(text)\n",
    "            documents.append(json_line['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3-hPHhHa12V"
   },
   "source": [
    "Train a new word vector model for the WMD similarity and then use it for the Word similarity model (WMD). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24036,
     "status": "ok",
     "timestamp": 1610526209111,
     "user": {
      "displayName": "Aobo Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1R4n3TLad19eGDFJcbKQpak37bv0BcjEpPoimgw=s64",
      "userId": "18082252328038546601"
     },
     "user_tz": -480
    },
    "id": "OZrtx4J2AK-p",
    "outputId": "6e764cd7-6252-4031-a069-8c450e322904"
   },
   "outputs": [],
   "source": [
    "# Train Word2Vec on all the restaurants. \n",
    "n_model = Word2Vec(w2v_corpus, workers=3, size=100, min_count=1)\n",
    "\n",
    "# Initialize WmdSimilarity.\n",
    "from gensim.similarities import WmdSimilarity\n",
    "num_best = 5\n",
    "instance = WmdSimilarity(wmd_corpus, model, num_best=5)  # means the top 5 documents are retrieved\n",
    "# possible sentences come from only the wmd_corpus.\n",
    "# WMD based on the word2vec from w2c corpus.\n",
    "# you must first build vocabulary before training the model --> usually due to empty w2v_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PniPD48OiXd4"
   },
   "source": [
    "Test it on one of the review sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 808,
     "status": "ok",
     "timestamp": 1610526222479,
     "user": {
      "displayName": "Aobo Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1R4n3TLad19eGDFJcbKQpak37bv0BcjEpPoimgw=s64",
      "userId": "18082252328038546601"
     },
     "user_tz": -480
    },
    "id": "zKX5jPjjAK-p",
    "outputId": "81d6d805-5882-4613-daf6-ec5d39c20c8a"
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "sent = 'love the gyro plate. Rice is so good and I also dig their candy selection.'\n",
    "query = preprocess(sent)\n",
    "sims = instance[query]  # A query is simply a \"look-up\" in the similarity class.\n",
    "print ('Cell took %.2f seconds to run.' %(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6klmHw9Diale"
   },
   "source": [
    "Output the num_best sentences that are most similar to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 829,
     "status": "ok",
     "timestamp": 1610526243189,
     "user": {
      "displayName": "Aobo Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1R4n3TLad19eGDFJcbKQpak37bv0BcjEpPoimgw=s64",
      "userId": "18082252328038546601"
     },
     "user_tz": -480
    },
    "id": "SWAt382zdPQy",
    "outputId": "82952a2d-34f3-4f28-a14e-f36a339e33d0"
   },
   "outputs": [],
   "source": [
    "# Print the query and the retrieved documents, together with their similarities.\n",
    "print ('Query:', sent)\n",
    "for i in range(num_best):\n",
    "    print (i, '----')\n",
    "    print (documents[sims[i][0]])\n",
    "    print ('sim = %.4f' % sims[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwatTRYxwow3"
   },
   "source": [
    "**Workshop submission:**\n",
    "\n",
    "Use the news.xls corpus to replace the yelp academic dataset to re-construct a word vector model. Lets call this word vector model WV_News and the word vector model from Yelp reviews WV_Yelp. \n",
    "\n",
    "\n",
    "*   Get the most similar document for the following two sentences from two models (Yelp & WV_NEWS):\n",
    "\n",
    "\n",
    "sentence_1: The pandemic is showing little sign of slowing down, with more than 10,000 new deaths recorded worldwide every day. according to an AFP tally.\n",
    "\n",
    "Yelp doc:\n",
    "\n",
    "WV_NEWS doc:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Sentence_2:The dollar's weakening is likely to last at least another six months as investors continue to shift to risky assets and higher returns from a Reuters poll.\n",
    "\n",
    "Yelp doc:\n",
    "\n",
    "WV_NEWs doc:\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "*   Comment on your findings. For eg. On the choice of words, the usage/ size of the corpus  all these can affect the results). Does a different word vector corpus affect also the similarity scores? Also, on the extracted news sentence outcome. Does it look suitable?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfIiffjtw8-v"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP 3.3 Document Similarity.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
